root_path: "C:\\Users\\AbsoluteZero\\Desktop\\Chest_Dataset\\Chest_Dataset_Resize"

## Chest14: C:\\Users\\AbsoluteZero\\Desktop\\Chest_Dataset\\Chest_Dataset_Resize
## CheXpert: C:\\Users\\AbsoluteZero\\Desktop\\CheXpert-v1.0-small

mode: "train"

data:
  size: [224, 224]

model:
  model_type: "resnet50"
  number_classes: 15

## chex_small - does a smaller amount because teh dataset was too big for testing
## chest14 - does entire dataset
## chex - when you want to do the entire dataset

train:
  name: "chest14"
  data_path: "C:\\Users\\AbsoluteZero\\Desktop\\Chest_Dataset\\Chest_Dataset_Resize"
  start_epoch: 0
  end_epoch: 6
  batch: 16
  num_workers: 0
  chkpnt_step: 5
  loss:
  metric: "proxy"

## loss: bce , cel , wcel
## metric: contrastive , triplet , or blank for none


  learning_rate:
    momentum: 0.9
    decay: 0.5
    base_rate: 0.0001
    steps: 10

## Chest14: C:\\Users\\AbsoluteZero\\Desktop\\Chest_Dataset\\Chest_Dataset_Resize
## CheXpert: C:\\Users\\AbsoluteZero\\Desktop\\CheXpert-v1.0-small
## chex_small
## chest14

test:
  name: "chest14"
  dataset_path: "C:\\Users\\AbsoluteZero\\Desktop\\Chest_Dataset\\Chest_Dataset_Resize"
  checkpoint_path: "C:\\Users\\AbsoluteZero\\thesis\\training_logs\\"
  batch: 128
  num_workers: 0


experiment_name: "proxy_no_cel_no_smooth_doubleclass"
log_dir: "C:\\Users\\AbsoluteZero\\thesis\\training_logs"



  # batchsize = [64]  # [64, 128, 256, 512]
  # learningrate = [1e-3, 1e-4, 1e-5]