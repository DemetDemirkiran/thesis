root_path: "/home/demet/Desktop/CheXpert-v1.0-small"

## Chest14: /home/demet/Desktop/Chest_Dataset/Chest_Dataset_Resize
## CheXpert: /home/demet/Desktop/CheXpert-v1.0-small

mode: "train"

data:
  size: [224, 224]

model:
  model_type: "cbam"
  number_classes: 15

## chex_small
## chest14

train:
  name: "chex_small"
  data_path: "/home/demet/Desktop/CheXpert-v1.0-small"
  start_epoch: 0
  end_epoch: 31
  batch: 16
  num_workers: 0
  chkpnt_step: 5
  loss: "bce"

  learning_rate:
    momentum: 0.9
    decay: 0.5
    base_rate: 0.0001
    steps: 10

## Chest14: /home/demet/Desktop/Chest_Dataset/Chest_Dataset_Resize
## CheXpert: /home/demet/Desktop/CheXpert-v1.0-small
## chex_small
## chest14

test:
  name: "chest14"
  dataset_path: "/home/demet/Desktop/CheXpert-v1.0-small"
  checkpoint_path: "/home/demet/PycharmProjects/thesis/training_logs/chest14/bcecbam_lr0.0001_bs16/5.pth"
  batch: 128
  num_workers: 0


experiment_name: "bce"
log_dir: "/home/demet/PycharmProjects/thesis/training_logs"



  # batchsize = [64]  # [64, 128, 256, 512]
  # learningrate = [1e-3, 1e-4, 1e-5]
